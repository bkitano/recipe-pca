{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipes PCA\n",
    "### By Brian Kitano\n",
    "\n",
    "Okay, I'm going to use the Epicurious dataset to identify palates common across their recipes. \n",
    "\n",
    "### Naming conventions of variables\n",
    "1. The raw dataset is loaded as an array called `data`, but we will exclusively use the dictionary `titleToRawRecipe` which contains a mapping of recipe titles to their data.\n",
    "2. There are three kinds of ingredient objects: `rawIngredient` is the original ingredient string as it is found in `titleToRawRecipe`; `cleanIngredient` is the ingredient after NLP cleaning; and `cookedIngredient` is the dictionary object returned by the CRF.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction / Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Materials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure\n",
    "1. Download the JSON data\n",
    "2. Parse the JSON to extract recipe names and ingredients with their quantities.\n",
    "3. Create the data matrix M, where each column is a recipe and each row is an ingredient; the entry is the quantity in a normalized and standardized quantity (grams?)\n",
    "4. PCA\n",
    "\n",
    "Bonus: construct the bipartite graph of ingredients to recipes, and then project it down onto a unipartite graph of ingredients where the weight of each edge is the frequency of connections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20130\n",
      "20111\n",
      "20111\n"
     ]
    }
   ],
   "source": [
    "# 1. Parse the ingredients to extract recipe names and ingredients with their quantities\n",
    "import json\n",
    "\n",
    "# load in the epicurious set\n",
    "with open('full_format_recipes.json') as f:\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "    \n",
    "# print data[0]['ingredients']\n",
    "print len(data)\n",
    "\n",
    "# need to filter out the recipes without a title\n",
    "data = list(filter(lambda recipe: 'title' in recipe.keys(), data)) \n",
    "print len(data)\n",
    "\n",
    "# need to filter out the recipes that don't have ingredients listed\n",
    "data = list(filter(lambda recipe: 'ingredients' in recipe.keys(), data))\n",
    "print len(data)\n",
    "\n",
    "# as a simple means of cleaning everything, let's strip whitespace from all the listings\n",
    "for recipe in data:\n",
    "    ingredients = recipe['ingredients']\n",
    "    for ingredient in ingredients:\n",
    "        ingredient = ingredient.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17775\n"
     ]
    }
   ],
   "source": [
    "# there are duplicate recipes lol\n",
    "# start by making the hash map of title to recipe\n",
    "titleToRawRecipe = dict()\n",
    "\n",
    "# for a recipe in the dataset\n",
    "for recipe in data:\n",
    "    title = recipe['title']\n",
    "    # if we haven't seen that recipe before, add it to the dictionary\n",
    "    if title not in titleToRawRecipe.keys():\n",
    "        titleToRawRecipe[title] = recipe\n",
    "        # otherwise, doesn't matter, ignore it\n",
    "\n",
    "# from then on out, we can only work with the dictionary\n",
    "print len(titleToRawRecipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180467\n"
     ]
    }
   ],
   "source": [
    "# get all of the ingredient lists as a list of lists\n",
    "rawIngredientsLists = [ titleToRawRecipe[titleToRawRecipe.keys()[i]]['ingredients'] for i in range(len(titleToRawRecipe)) ]\n",
    "\n",
    "# flatten this list, which might contain duplicates\n",
    "rawIngredients = [ ingredient for ingredientList in rawIngredientsLists for ingredient in ingredientList]\n",
    "print len(rawIngredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to deal with the redundancy neatly. What we can do is map each original listing to a number, in another dictionary map that number to a processed listing. Then we only have to work with the processed listings and not fuck with the original mapping. We'll need to make a temporary reverse mapping of the set list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82097\n",
      "82097\n"
     ]
    }
   ],
   "source": [
    "# a deduplicated list of ingredients\n",
    "uniqueRawIngredients = list(set(rawIngredients))\n",
    "print len(uniqueRawIngredients)\n",
    "\n",
    "# a temporary map from cleaned ingredient to index\n",
    "uniqueRawIngredientToIndex = dict(zip(uniqueRawIngredients, range(len(uniqueRawIngredients))))\n",
    "\n",
    "# now create a map from the original ingredients to these indices\n",
    "rawIngredientToIndex = dict()\n",
    "for ingredient in rawIngredients:\n",
    "    rawIngredientToIndex[ingredient] = uniqueRawIngredientToIndex[ingredient]\n",
    "    \n",
    "print len(rawIngredientToIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there's a mapping of the original listing to the unique listing, so we can safely process the unique list without losing track of where the original ones came from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "Before we write all of the ingredients to a file, we should do some NLP cleaning. In looking at the results of the first model run, it seems like to be conservative we should remove all the text that occurs in parentheses, as this seems to really mess up the CRF's ability to identify units. One unfortunate consequence is that we'll no longer be able to filter lists using lambdas, but instead replace them with null strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove things in parentheses (use regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82097\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# remove all the text that is inside a parenthesis\n",
    "noParenthesisIngredients = [re.sub('\\s*\\([^)]*\\)', '', ingredient) for ingredient in uniqueRawIngredients]\n",
    "\n",
    "print len(noParenthesisIngredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dealing with the word \"plus\"\n",
    "\n",
    "More complex problem. There are lots of ways that \"plus\" is used. Some examples:\n",
    "\n",
    "##### when quantities don't add nicely\n",
    "- \"1/2 cup plus 1 1/2 tablespoons red wine vinegar\"\n",
    "- \"1/2 cup plus 2 tablespoons granola\"\n",
    "- \"1/4 cup plus 1 tablespoon warm water\"\n",
    "- \"1/4 teaspoon plus 1/3 cup sugar\"\n",
    "- \"2 tablespoons plus 1/2 cup chopped fresh dill\"\n",
    "- \"1 tablespoon plus 1/2 teaspoon Dijon mustard\"\n",
    "- \"2/3 cup plus 6 tablespoons coarsely chopped pecans\"\n",
    "- \"1 cup plus 2 tablespoons whole milk\"\n",
    "- \"1 1/2 cups plus 2 tablespoons sugar\"\n",
    "- \"1 1/2 cups plus 2 tablespoons water\"\n",
    "- \"1 tablespoon plus 3/4 teaspoon ground cinnamon\"\n",
    "- \"1 tablespoon plus one teaspoon fresh lemon juice\"\n",
    "\n",
    "These are in a consistent format of UNIT QUANTITY PLUS UNIT QUANTITY INGREDIENT. If we add PLUS as a label, then over the 3k samples we have we might improve, but we might also tag some things as being PLUS when we don't want them to be.\n",
    "\n",
    "##### when there's a suggestion for more on the side (not a lot of errors there)\n",
    "- \"1/4 cup olive oil, plus more for grilling\"\n",
    "- \"5 teaspoons all-purpose flour plus more for dusting\"\n",
    "- \"2 tablespoons drained capers plus more for serving\"\n",
    "- \"1/2 cup freshly grated Parmesan cheese plus additional for passing\"\n",
    "- \"12 rice-paper rounds, plus more in case some tear\"\n",
    "- \"1 can whole tomatoes, plus juice\"\n",
    "- \"1 tablespoon chile oil containing sesame oil plus some of sediment from jar\"\n",
    "\n",
    "These ones seem like i can just remove all the words after the plus.\n",
    "\n",
    "##### other, stupid ones\n",
    "- \"8 cornichons, finely chopped, plus 2 pickled onions from the jar, minced\"\n",
    "- \"1/2 cup oil-packed sun-dried tomatoes, chopped, plus 2 tablespoons tomato oil\"\n",
    "- \"1 tablespoon fresh rosemary leaves or 1 teaspoon crumbled dried, plus rosemary sprigs for garnish\"\n",
    "- \"Juice of 1/4 lime, plus 1 lime wedge for garnish\"\n",
    "- \"1 1/2 cups sugar, plus 1/4 cup mixed with 1 tablespoon cinnamon, on a plate\"\n",
    "- \"1/2 fennel bulb, finely chopped, plus 1 tablespoon finely chopped fronds\"\n",
    "- \"1/4 cup chopped fresh cilantro plus 32 whole fresh cilantro leaves\"\n",
    "- \"6 large celery stalks, thickly sliced, plus 2 1/2 cups 1/2-inch-thick slices\"\n",
    "- \"6 fresh mint leaves plus 1 mint sprig for garnish\"\n",
    "\n",
    "So also there's like a utility function that might need to be taken into account: we really want our data to fit the format nicely of having a name, a unit, and a quantity. \n",
    "\n",
    "A really, really easy way to deal with all of this is just to get rid of all the \"plus\" ingredient listings, which are only ~3000 out of the 83k samples. It might mess up the data but it's easier. Also none of this is training or testing data, this is like actually \"I need this\" data so it's convenient if I just scrap the shitty stuff. It will also probably have come up in other sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82097"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we use a regex to tag an igredient any time \"plus\" appears as a word with or without a comma on its own\n",
    "def removePlus(ingredient):\n",
    "    if (re.search(\"\\s*(plus)\\,*\\s*\", ingredient) == None):\n",
    "        return ingredient\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "noPlusListings = [removePlus(ingredient) for ingredient in noParenthesisIngredients]\n",
    "\n",
    "len(noPlusListings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case sensitivity\n",
    "\n",
    "we need to make everything lower case. has to happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82097"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caseInsensitiveListings = [ ingredient.lower() for ingredient in noPlusListings ] \n",
    "len(caseInsensitiveListings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dashes, commas, and other grammar thingies\n",
    "might be worth removing all of that, but not going to yet. \n",
    "\n",
    "##### Asterisks (*)\n",
    "Asterisks appear in two variants:\n",
    "\"2 1/2 pounds Jerusalem artichokes *\" where the asterisk is at the end, and \"*seedless red grapes\" where it's indicating that this is the start of a comment. We can thus remove anything after an asterisk, since it doesn't matter in either case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82097\n"
     ]
    }
   ],
   "source": [
    "# removing all the text after an asterisk\n",
    "asteriskFreeListings = [ re.sub(\"\\*.*\\n*\",'',ingredient) for ingredient in caseInsensitiveListings ]\n",
    "print len(asteriskFreeListings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Commas (,)\n",
    "We might need to clear off all the commas, because I think it's fucking up the parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82097\n"
     ]
    }
   ],
   "source": [
    "# remove all the commas from the thing\n",
    "commaFreeListings = [ re.sub('\\,', '', ingredient) for ingredient in asteriskFreeListings ]\n",
    "print len(commaFreeListings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dashes (-)\n",
    "We should def remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all the dashes from ingredients\n",
    "dashFreeListings = [ re.sub('-', ' ', ingredient) for ingredient in commaFreeListings]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strip non ascii characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "asciiOnlyListings = [ \"\".join(i for i in ingredient if ord(i)<128) for ingredient in dashFreeListings ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THIS IS THE REAL PROBLEM\n",
    "The model parses for tokens first, so there's never any extra white space. We need to strip the extra white space from every word!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmedListings = [\" \".join( ingredient.split() ) for ingredient in asciiOnlyListings]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"a\" and \"an\"\n",
    "This probably maps to the number 1 right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### typos\n",
    "\n",
    "like fam what how is that even ugh how do i check for typos here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"or\"\n",
    "we could remove all the tokens after the word \"or\", since it's optional.\n",
    "\n",
    "examples:\n",
    "- 1 cup fresh or frozen cranberries (about 4 ounces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82097\n"
     ]
    }
   ],
   "source": [
    "# remove all the things after an or\n",
    "noOrListings = [ re.sub(\"\\.*\\,*\\s*(or|OR|Or)+\\,*\\s+.*\",'', ingredient) for ingredient in trimmedListings ]\n",
    "\n",
    "print len(noOrListings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that our mapping methods are still valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 oz extra-sharp reduced-fat Cheddar (made from 2% milk), coarsely grated\n",
      "4 oz extra sharp reduced fat cheddar coarsely grated\n",
      "\n",
      "\n",
      "12 large fennel bulbs, trimmed, halved lengthwise, cored, sliced crosswise\n",
      "12 large fennel bulbs trimmed halved lengthwise cored sliced crosswise\n",
      "\n",
      "\n",
      "1 pork tenderloin\n",
      "1 pork tenderloin\n",
      "\n",
      "\n",
      "2 lb medium shrimp in shell (31 to 35 per pound), peeled and deveined\n",
      "2 lb medium shrimp in shell peeled and deveined\n",
      "\n",
      "\n",
      "2 tablespoon white wine vinegar\n",
      "2 tablespoon white wine vinegar\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's make a function to make our lives easier for doing lookup\n",
    "def getCleanedIngredientFromRawIngredient(rawIngredient, uniqueList):\n",
    "    index = rawIngredientToIndex[rawIngredient]\n",
    "    return uniqueList[index]\n",
    "\n",
    "for i in range(20,25):\n",
    "    print uniqueRawIngredients[i]\n",
    "    print getCleanedIngredientFromRawIngredient( uniqueRawIngredients[i] , noOrListings)\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'5 or 6 ice cubes'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getCleanedIngredientFromRawIngredient('5 or 6 ice cubes', trimmedListings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw: 4 oz extra-sharp reduced-fat Cheddar (made from 2% milk), coarsely grated, 20\n",
      "cleaned: 4 oz extra sharp reduced fat cheddar coarsely grated, 20\n",
      "raw: 12 large fennel bulbs, trimmed, halved lengthwise, cored, sliced crosswise, 21\n",
      "cleaned: 12 large fennel bulbs trimmed halved lengthwise cored sliced crosswise, 21\n",
      "raw: 1 pork tenderloin, 22\n",
      "cleaned: 1 pork tenderloin, 61194\n",
      "raw: 2 lb medium shrimp in shell (31 to 35 per pound), peeled and deveined, 23\n",
      "cleaned: 2 lb medium shrimp in shell peeled and deveined, 23\n",
      "raw: 2 tablespoon white wine vinegar, 24\n",
      "cleaned: 2 tablespoon white wine vinegar, 24\n"
     ]
    }
   ],
   "source": [
    "# now we make a hash map from the cleaned inputs to their index\n",
    "cleanedIngredientToIndex = dict(zip(noOrListings, range(len(noOrListings))))\n",
    "\n",
    "# show that the originalIndex and the cleanedIndex are the same\n",
    "for i in range(20,25):\n",
    "    rawIngredient = uniqueRawIngredients[i]\n",
    "    cleanedIngredient = getCleanedIngredientFromRawIngredient(rawIngredient, noOrListings)\n",
    "    print \"raw: \" + rawIngredient + \", \" + str(rawIngredientToIndex[rawIngredient])\n",
    "    print \"cleaned: \" + cleanedIngredient + \", \" + str(cleanedIngredientToIndex[cleanedIngredient])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so how will we get from the modeled stuff to the original recipe?\n",
    "\n",
    "1. map json to listing index\n",
    "\n",
    "1a. map model json to input to model aka cleanedListing\n",
    "\n",
    "1b. map cleanedListing to index\n",
    "\n",
    "2. map original listing to listing index (done)\n",
    "3. reverse map listing index to json\n",
    "\n",
    "and then i think we're good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let's write this clean stuff to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the ingredients to a file, which we'll then feed to a model\n",
    "with open('ingredientsList.txt', 'a') as the_file:\n",
    "    for ingredient in noOrListings:\n",
    "        if ingredient != \"\":\n",
    "            the_file.write(ingredient + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemon juice\n",
      "cup\n",
      "1 1/4\n",
      "78759\n"
     ]
    }
   ],
   "source": [
    "# okay, the model ran and i've got the sauce\n",
    "\n",
    "# load in the labeled stuff\n",
    "with open('results.json') as g:\n",
    "    cookedIngredients = json.load(g)\n",
    "    g.close()\n",
    "    \n",
    "print cookedIngredients[0]['name']\n",
    "print cookedIngredients[0]['unit']\n",
    "print cookedIngredients[0]['qty']\n",
    "\n",
    "print len(cookedIngredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a mapping from cleaned listing to model\n",
    "cleanedIngredientToCookedIngredient = dict()\n",
    "for cookedIngredient in cookedIngredients:\n",
    "    cleanedIngredient = cookedIngredient['input'] # this isn't necessarily the cleanedIngredient, if it writes weird\n",
    "    cleanedIngredientToCookedIngredient[cleanedIngredient] = cookedIngredient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titleToCookedRecipe is a mapping from title to recipe containing cooked ingredients\n",
    "titleToCookedRecipe = dict()\n",
    "\n",
    "# for every recipe title\n",
    "for recipe in titleToRawRecipe.values():\n",
    "    title = recipe['title']\n",
    "    # create an empty list to store the ingredients\n",
    "    cookedIngredients = list()\n",
    "    # for every ingredient in that recipe\n",
    "    for rawIngredient in recipe['ingredients']:\n",
    "\n",
    "        # get the cleaned listing\n",
    "        cleanedIngredient = getCleanedIngredientFromRawIngredient(rawIngredient, noOrListings)\n",
    "        \n",
    "        # get the model based on the cleaned listing\n",
    "        try:\n",
    "            cookedIngredient = cleanedIngredientToCookedIngredient[cleanedIngredient]\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "        # append that model to the list\n",
    "        cookedIngredients.append(cookedIngredient)\n",
    "    # enter the title and the list into the dictionary as key value pairs\n",
    "    titleToCookedRecipe[title] = cookedIngredients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the cleanedIngredientToCookedIngredient dictionary isn't working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'input': u'2 ounces manchego cheese', u'qty': u'2', u'display': u\"<span class='qty'>2</span><span class='unit'>ounces</span><span class='name'>manchego cheese</span>\", u'unit': u'ounce', u'name': u'manchego cheese'}\n"
     ]
    }
   ],
   "source": [
    "cleanedIngredient = getCleanedIngredientFromRawIngredient('2 ounces Manchego cheese,* grated', noOrListings)\n",
    "print cleanedIngredientToCookedIngredient[cleanedIngredient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "butternut squash quartered seeded peeled and cut into 1/2 inch dice\n",
      "vegetable oil\n",
      "milk\n",
      "rosemary\n",
      "garlic\n",
      "unsalted butter\n",
      "all purpose flour\n",
      "nine 7 by 3 1/2 inch sheets dry no boil lasagne pasta\n",
      "{u'comment': u'freshly grated', u'input': u'1 1/3 cups freshly grated parmesan', u'other': u'1 1/3 parmesan', u'display': u\"<span class='other'>1 1/3</span><span class='unit'>cups</span><span class='comment'>freshly grated</span><span class='other'>parmesan</span>\", u'unit': u'cup'}\n",
      "heavy cream\n",
      "salt\n",
      "rosemary\n",
      "17775\n"
     ]
    }
   ],
   "source": [
    "for cookedIngredient in titleToCookedRecipe['Roasted Butternut Squash, Rosemary, and Garlic Lasagne ']:\n",
    "    try:\n",
    "        print cookedIngredient['name']\n",
    "    except:\n",
    "        print cookedIngredient\n",
    "        pass\n",
    "    \n",
    "print len(titleToCookedRecipe.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some cookedIngredients don't have fricken names. Need to deal with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedTitleToCookedRecipe = dict()\n",
    "for cookedRecipeTitle in titleToCookedRecipe.keys():\n",
    "    cleanedCookedIngredients = list()\n",
    "    for cookedIngredient in titleToCookedRecipe[cookedRecipeTitle]:\n",
    "        try:\n",
    "            name = cookedIngredient['name']\n",
    "            cleanedCookedIngredients.append(cookedIngredient)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    cleanedTitleToCookedRecipe[cookedRecipeTitle] = cleanedCookedIngredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178696\n"
     ]
    }
   ],
   "source": [
    "# extract all of the ingredients in all of the recipes\n",
    "allCookedIngredients = [ cookedIngredient['name'] for recipe in cleanedTitleToCookedRecipe.values() for cookedIngredient in recipe ]\n",
    "print len(allCookedIngredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueCookedIngredients = list(set(allCookedIngredients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a count of each ingredient\n",
    "ingredientHistogram = dict()\n",
    "for ingredient in allCookedIngredients:\n",
    "    if ingredient not in ingredientHistogram.keys():\n",
    "        ingredientHistogram[ingredient] = 1\n",
    "    else:\n",
    "        ingredientHistogram[ingredient] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a histogram of ingredients to see the count and trim the ingredients that just don't have that many entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedIngredientHistogram = sorted(ingredientHistogram.iteritems(), key=lambda (k,v): (v,k), reverse=True)\n",
    "sortedIngredientHistogramDict = dict(sortedIngredientHistogram[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178696\n",
      "135312\n"
     ]
    }
   ],
   "source": [
    "print sum([sortedIngredientHistogram[i][1] for i in range(len(sortedIngredientHistogram))])\n",
    "print sum(sortedIngredientHistogramDict.values())\n",
    "\n",
    "# accounts for 71% for of the ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to group the recipes back to the most common ingredients\n",
    "servedTitleToCookedRecipe = dict()\n",
    "for title in cleanedTitleToCookedRecipe.keys():\n",
    "    recipe = cleanedTitleToCookedRecipe[title]\n",
    "    servedIngredients = list()\n",
    "    for ingredient in recipe:\n",
    "        try: \n",
    "            sortedIngredientHistogramDict[ingredient['name']]\n",
    "            servedIngredients.append(ingredient)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    servedTitleToCookedRecipe[title] = servedIngredients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So `servedTitleToCookedRecipe` is a dictionary containing unique non-duplicated recipes, and each recipe contains only the 400 most popular ingredients. We can now construct our matrix, I think. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need a map from unique ingredient to index\n",
    "servedIngredientToIndex = dict( zip( sortedIngredientHistogramDict.keys(), range(len(sortedIngredientHistogramDict)) ) )\n",
    "\n",
    "# need a map from unique recipe name to index\n",
    "servedRecipeToIndex = dict( zip( servedTitleToCookedRecipe.keys(), range(len(servedTitleToCookedRecipe))))\n",
    "\n",
    "I = len(servedIngredientToIndex)\n",
    "R = len(servedRecipeToIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know the dimensions of our data matrix: each recipe is a 400-dimensional vector, and we have 17775 samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000: 0.814419031143\n",
      "2000: 2.17674207687\n",
      "3000: 2.61970090866\n",
      "4000: 3.59014201164\n",
      "5000: 4.20217990875\n",
      "6000: 6.58846020699\n",
      "7000: 8.2196419239\n",
      "8000: 9.37850403786\n",
      "9000: 10.9963028431\n",
      "10000: 11.806718111\n",
      "11000: 42.4183828831\n",
      "12000: 76.9835460186\n",
      "13000: 84.6163311005\n",
      "14000: 92.9993798733\n",
      "15000: 99.1833441257\n",
      "16000: 103.797976017\n",
      "17000: 110.000628948\n",
      "Total time: 759.786216974\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# for parsing fractions\n",
    "from fractions import Fraction\n",
    "\n",
    "# create an numpy array to store the vectors, R rows x I columns\n",
    "D = np.zeros((400,1))\n",
    "\n",
    "start = time.time()\n",
    "prev = time.time()\n",
    "# going to ignore scaling for now just for proof of concept\n",
    "for title in servedTitleToCookedRecipe.keys():\n",
    "    \n",
    "    row = servedRecipeToIndex[title]\n",
    "    recipeVector = np.zeros((I, 1)) # 400 x 1 column vector which we'll transpose later\n",
    "    \n",
    "    recipe = servedTitleToCookedRecipe[title]\n",
    "    for ingredient in recipe:\n",
    "        \n",
    "        col = servedIngredientToIndex[ingredient['name']]\n",
    "        \n",
    "        try:\n",
    "            qty = float(sum(Fraction(s) for s in ingredient['qty'].split()))\n",
    "            recipeVector[col] += qty\n",
    "            \n",
    "        except:\n",
    "            recipeVector[col] += 1\n",
    "        \n",
    "    Dx = np.vstack((D.transpose(), recipeVector.transpose()))\n",
    "    D = Dx.transpose()\n",
    "    if np.size(D, 1) % 1000 == 0:\n",
    "        curr = time.time()\n",
    "        print str(np.size(D,1)) + \": \" + str(curr - prev)\n",
    "        prev = curr\n",
    "\n",
    "end = time.time()\n",
    "print \"Total time: \" + str(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 17776)\n"
     ]
    }
   ],
   "source": [
    "print D.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so `D` is now the data matrix we've been waiting for. We now have to do PCA on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labeledIngredients' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c6ed1481c74b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# get all of the indices which contain units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0munitContainingIndices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcontainsUnit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeledIngredients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0munitContainingIndices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munitContainingIndices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labeledIngredients' is not defined"
     ]
    }
   ],
   "source": [
    "# now we need to normalize all of the units and measures. We'll use milliliters for volume and grams for mass.\n",
    "\n",
    "# first we'll get a list of all the units\n",
    "def containsUnit(i):\n",
    "    if 'unit' in cookedIngredients[i].keys():\n",
    "        return i\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# get all of the indices which contain units\n",
    "unitContainingIndices = [containsUnit(i) for i in range(len(labeledIngredients))]\n",
    "unitContainingIndices = list(set(unitContainingIndices))\n",
    "\n",
    "# get all of the units\n",
    "unitList = [labeledIngredients[i]['unit'] for i in list(set(unitContainingIndices))]\n",
    "\n",
    "# remove duplicates\n",
    "uniqueUnitList = list(set(unitList))\n",
    "\n",
    "print len(uniqueUnitList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre and Post Modeling Cleaning\n",
    "What cleaning should be done before we feed the model, and what cleaning should be done after? Also, should we change our factor functions? \n",
    "\n",
    "Well, let's think quantitatively about what cleaning means now. We've identified the units from the model, and they're obviously not perfect. We should look at whether we can just cut the shitty ones out now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary mapping unit to ingredients\n",
    "sortedIngredientsByUnit = dict()\n",
    "\n",
    "for ingredient in labeledIngredients:\n",
    "    unit = 'na'\n",
    "    # if there's a unit associated with the ingredient\n",
    "    if 'unit' in ingredient.keys():\n",
    "        unit = ingredient['unit']\n",
    "    \n",
    "    if isinstance(ingredient, dict):\n",
    "        # if that unit is already in the dictionary\n",
    "        if unit in sortedIngredientsByUnit.keys():\n",
    "            sortedIngredientsByUnit[unit].append(ingredient)\n",
    "        else:\n",
    "            # that unit is unseen, so we need to create it\n",
    "            sortedIngredientsByUnit[unit] = [ingredient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unitByCount = dict()\n",
    "\n",
    "for unit in sortedIngredientsByUnit.keys():\n",
    "    unitByCount[unit] = len(sortedIngredientsByUnit[unit])\n",
    "    \n",
    "unitByCountSorted = sorted(unitByCount.iteritems(), key=lambda (k,v): (v,k), reverse=True)\n",
    "\n",
    "print unitByCountSorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I think since the first 25 units account for ~99% of the ingredients in the set, I'm just gonna drop the remaining ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unitByCountTruncated = dict(unitByCountSorted[:25])\n",
    "print unitByCountTruncated\n",
    "print sum(unitByCountTruncated.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, i'm not really sure how my previous work is that helpful. Anyways, what I need to do now is reassociate each recipe with its ingredients, now modeled. I think I'll have to make a new dictionary, where keys are titles, and the modeled ingredients are values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
